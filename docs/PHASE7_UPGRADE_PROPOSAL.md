# Phase 7ï¼šä½¿ç”¨è€…é«”é©—èˆ‡æ™ºèƒ½åŒ–å‡ç´šææ¡ˆ

> æ’°å¯«æ—¥æœŸï¼š2026-02-09
> èƒŒæ™¯ï¼šPhase 6 å®Œæˆ AI å¼•æ“å‡ç´šï¼ˆLlamaParse + jieba + HyDE + LLM ç”Ÿæˆ + Chunk å»é‡ï¼‰å¾Œï¼Œç³»çµ±åœ¨è³‡æ–™è™•ç†èˆ‡ RAG æª¢ç´¢å·²é”é«˜æ°´æº–ã€‚æœ¬ææ¡ˆèšç„¦**ä½¿ç”¨è€…äº’å‹•é«”é©—**é¢å‘çš„å…¨é¢å¼·åŒ–ã€‚

---

## ç›®éŒ„

- [ç¾æ³å·®è·åˆ†æ](#ç¾æ³å·®è·åˆ†æ)
- [å‡ç´šç¸½è¦½](#å‡ç´šç¸½è¦½)
- [P0ï¼šStreaming SSE é€å­—è¼¸å‡º](#p0streaming-sse-é€å­—è¼¸å‡º)
- [P0ï¼šMulti-turn Context å¤šè¼ªå°è©±è¨˜æ†¶](#p0multi-turn-context-å¤šè¼ªå°è©±è¨˜æ†¶)
- [P1ï¼šChat UX å…¨é¢å‡ç´š](#p1chat-ux-å…¨é¢å‡ç´š)
- [P2ï¼šMobile Responsive](#p2mobile-responsive)
- [P2ï¼šå°è©±åŒ¯å‡º + é€²éšåˆ†æ](#p2å°è©±åŒ¯å‡º--é€²éšåˆ†æ)
- [æŠ•å…¥å›å ±åˆ†æ](#æŠ•å…¥å›å ±åˆ†æ)
- [æŠ€è¡“åƒè€ƒè³‡æº](#æŠ€è¡“åƒè€ƒè³‡æº)
- [å¯¦ä½œæ’ç¨‹å»ºè­°](#å¯¦ä½œæ’ç¨‹å»ºè­°)

---

## ç¾æ³å·®è·åˆ†æ

### å·²å®Œæˆçš„å„ªå‹¢

| ç¶­åº¦ | ç›®å‰èƒ½åŠ› |
|------|----------|
| æ–‡ä»¶è§£æ | 23 ç¨®æ ¼å¼ï¼ŒLlamaParse å„ªå…ˆ + åŸç”Ÿé™ç´š |
| æª¢ç´¢å¼•æ“ | Semantic + BM25ï¼ˆjiebaï¼‰+ RRF + Voyage Rerank-2 |
| æŸ¥è©¢æ“´å±• | HyDE å‡è¨­æ€§æ–‡ä»¶ï¼ˆèªæ„/æ··åˆæ¨¡å¼ï¼‰ |
| LLM ç”Ÿæˆ | GPT-4o-miniï¼Œåš´æ ¼å¼•ç”¨é™åˆ¶ + fallback æ¨¡æ¿ |
| Chunk å»é‡ | Per-document SHA256 é›œæ¹Š |
| å¤šç§Ÿæˆ¶éš”é›¢ | DB/Vector/File/API/Cache äº”å±¤éš”é›¢ |
| å®‰å…¨æ©Ÿåˆ¶ | JWT + SSO + ä¸‰å±¤é€Ÿç‡é™åˆ¶ + IP ç™½åå–® |
| ç›£æ§ | Prometheus + Grafana + å‘Šè­¦è¦å‰‡ |

### å¾…æ”¹é€²çš„ç—›é»

| ç¶­åº¦ | ç¾æ³ | å•é¡Œæè¿° | å½±éŸ¿ç¨‹åº¦ |
|------|------|----------|----------|
| **Chat å›æ‡‰æ–¹å¼** | ä¸€æ¬¡å›å‚³å®Œæ•´ JSON | ä½¿ç”¨è€…ç­‰ 5-15 ç§’åªçœ‹åˆ° spinner è½‰åœˆ | ğŸ”´ åš´é‡ |
| **å¤šè¼ªå°è©±** | æ¯æ¬¡æŸ¥è©¢ç¨ç«‹ï¼Œä¸å¸¶æ­·å² | è¿½å•ã€Œé‚£åŠ ç­è²»å‘¢ï¼Ÿã€å¤±å»ä¸Šä¸‹æ–‡ | ğŸ”´ åš´é‡ |
| **å›è¦†å‘ˆç¾** | `whitespace-pre-wrap` ç´”æ–‡å­— | è¡¨æ ¼ã€åˆ—è¡¨ã€ç²—é«”ç„¡æ³•æ­£ç¢ºæ¸²æŸ“ | ğŸŸ  ä¸­ç­‰ |
| **ä¾†æºå¼•ç”¨** | éœæ…‹ badge æ¨™ç±¤ | ç„¡æ³•é»é–‹æŸ¥çœ‹å…·é«”å¼•ç”¨æ®µè½èˆ‡æ³•æ¢ | ğŸŸ  ä¸­ç­‰ |
| **ä½¿ç”¨è€…å›é¥‹** | å®Œå…¨æ²’æœ‰ feedback æ©Ÿåˆ¶ | ç„¡æ³•é‡åŒ–å›ç­”å“è³ªã€ç„¡æ³•è¿­ä»£æ”¹å–„ | ğŸŸ  ä¸­ç­‰ |
| **è¡Œå‹•è£ç½®** | å´é‚Šæ¬„å›ºå®š 256px | æ‰‹æ©Ÿè¢å¹•ç„¡æ³•ä½¿ç”¨ | ğŸŸ¡ ä¸€èˆ¬ |
| **å°è©±åŒ¯å‡º** | ç„¡ | ä¼æ¥­åˆè¦å ´æ™¯éœ€è¦ | ğŸŸ¡ ä¸€èˆ¬ |
| **è¿½å•å¼•å°** | ç„¡ | ä½¿ç”¨è€…ä¸çŸ¥é“å¯ä»¥å•ä»€éº¼ | ğŸŸ¡ ä¸€èˆ¬ |

---

## å‡ç´šç¸½è¦½

```
Phase 7 å‡ç´šé …ç›®ï¼ˆ4 å¤§é …ï¼Œ11 å­ä»»å‹™ï¼‰

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     P0 æ ¸å¿ƒé«”é©—                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  T7-1 Streaming SSE â”‚ â”‚ T7-2 Multi-turn Context     â”‚â”‚
â”‚  â”‚  å¾Œç«¯ SSE ä¸²æµ       â”‚ â”‚ æ­·å²æ³¨å…¥ + Token ç®¡ç†        â”‚â”‚
â”‚  â”‚  å‰ç«¯é€å­—æ¸²æŸ“        â”‚ â”‚ æ»‘å‹•çª—å£ + æ‘˜è¦å£“ç¸®          â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                     P1 é«”é©—å¼·åŒ–                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ T7-3 Markdownâ”‚ â”‚ T7-4 Source  â”‚ â”‚ T7-5 Feedback    â”‚ â”‚
â”‚  â”‚ æ¸²æŸ“å¼•æ“     â”‚ â”‚ å¼•ç”¨å±•é–‹     â”‚ â”‚ ğŸ‘ğŸ‘ ç³»çµ±        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚  â”‚ T7-6 Follow  â”‚                                       â”‚
â”‚  â”‚ -up å»ºè­°     â”‚                                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                     P2 æ“´å±•åŠŸèƒ½                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ T7-9 Mobile  â”‚ â”‚ T7-11 Chat   â”‚ â”‚ T7-12 RAG       â”‚ â”‚
â”‚  â”‚ Responsive   â”‚ â”‚ Export       â”‚ â”‚ å“è³ªå„€è¡¨æ¿       â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚ T7-13 Chat   â”‚ â”‚ T7-14 Typing â”‚ â”‚                  â”‚ â”‚
â”‚  â”‚ æœå°‹         â”‚ â”‚ Indicator    â”‚ â”‚                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## P0ï¼šStreaming SSE é€å­—è¼¸å‡º

### å•é¡Œ

ç›®å‰ `POST /api/v1/chat` å›å‚³å®Œæ•´ JSONï¼Œä½¿ç”¨è€…é€å‡ºå•é¡Œå¾Œï¼š
1. å‰ç«¯é¡¯ç¤º `<Loader2 className="animate-spin" />` + ã€Œæ€è€ƒä¸­...ã€
2. ç­‰å¾… 5-15 ç§’ï¼ˆå«æª¢ç´¢ + Rerank + LLM ç”Ÿæˆï¼‰
3. å®Œæ•´å›ç­”ä¸€æ¬¡å‡ºç¾

**é€™æ˜¯ SaaS AI ç”¢å“æœ€å¤§çš„é«”é©—ç“¶é ¸** â€” ç«¶å“å¦‚ ChatGPTã€Claudeã€Perplexity å…¨éƒ¨æ¡ç”¨ä¸²æµè¼¸å‡ºã€‚

### æ–¹æ¡ˆ

#### T7-1ï¼šå¾Œç«¯ SSE ä¸²æµ + å‰ç«¯é€å­—æ¸²æŸ“

**å¾Œç«¯æ”¹å‹•**ï¼ˆ`chat_orchestrator.py` + `chat.py`ï¼‰ï¼š

> å‰ç½®é‡æ§‹ï¼ˆT7-0ï¼‰ï¼šç¾æœ‰ `process_query` ç¶å®šäº†æª¢ç´¢èˆ‡ç”Ÿæˆã€‚éœ€æ‹†åˆ†ç‚º `retrieve_context`ï¼ˆä¸¦è¡ŒæŸ¥è©¢å…§è¦+å‹å‹•æ³•ï¼‰èˆ‡ `generate_answer`ï¼ˆç´”ç”Ÿæˆï¼‰ï¼Œä»¥ä¾¿åœ¨ä¸²æµç«¯é»ä¸­åˆ†éšæ®µå‘¼å«ã€‚

```python
# app/api/v1/endpoints/chat.py â€” æ–°å¢ä¸²æµç«¯é»
from fastapi.responses import StreamingResponse

@router.post("/chat/stream")
async def chat_stream(request: ChatRequest, ...):
    orchestrator = ChatOrchestrator()
    
    async def event_generator():
        # Phase 1: å¿«é€Ÿå›é¥‹ â€” å‘ŠçŸ¥ä½¿ç”¨è€…ã€Œæ­£åœ¨æª¢ç´¢ã€
        yield f"data: {json.dumps({'type': 'status', 'content': 'æ­£åœ¨æœå°‹çŸ¥è­˜åº«...'})}\n\n"
        
        # Phase 2: æª¢ç´¢ï¼ˆåˆ†é›¢å‡ºçš„æª¢ç´¢é‚è¼¯ï¼‰
        # retrieve_context éœ€åŒ…å«ï¼šKB search + Core API call
        context_results = await orchestrator.retrieve_context(
            tenant_id=current_user.tenant_id, 
            question=request.question
        )
        
        # ç«‹å³å›å‚³ä¾†æºè³‡æ–™
        yield f"data: {json.dumps({'type': 'sources', 'sources': context_results['sources']})}\n\n"
        
        # Phase 3: LLM ä¸²æµç”Ÿæˆ
        yield f"data: {json.dumps({'type': 'status', 'content': 'æ­£åœ¨ç”Ÿæˆå›ç­”...'})}\n\n"
        
        async for chunk in orchestrator.stream_answer(
            question=request.question, 
            context_results=context_results
        ):
            yield f"data: {json.dumps({'type': 'token', 'content': chunk})}\n\n"
        
        # Phase 4: å®Œæˆ
        yield f"data: {json.dumps({'type': 'done', 'message_id': ...})}\n\n"
    
    headers = {
      "Cache-Control": "no-cache",
      "Connection": "keep-alive",
      # è‹¥èµ° Nginx/åå‘ä»£ç†ï¼Œå¸¸éœ€è¦é—œé–‰ buffering æ‰èƒ½å³æ™‚ä¸²æµ
      # "X-Accel-Buffering": "no",
    }
    return StreamingResponse(event_generator(), media_type="text/event-stream", headers=headers)
```

```python
# app/services/chat_orchestrator.py â€” é‡æ§‹èˆ‡æ–°å¢
class ChatOrchestrator:
    async def retrieve_context(self, tenant_id: UUID, question: str) -> Dict[str, Any]:
        """(T7-0) å¾ process_query æ‹†åˆ†å‡ºçš„ç´”æª¢ç´¢é‚è¼¯"""
        # ä¸¦è¡ŒåŸ·è¡Œï¼š
        # 1. self.kb_retriever.search(...)
        # 2. self.core_client.chat(...)
        # 3. åˆä½µçµæœä¸¦å›å‚³ (é¡ä¼¼åŸ _merge_results ä½†ä¸å«ç”Ÿæˆ)
        ...

    async def stream_answer(self, question: str, context_results: Dict[str, Any]):
        """(T7-1) ä¸²æµç”Ÿæˆ LLM å›ç­”"""
        # çµ„è£ Prompt (ä½¿ç”¨ context_results)
        messages = self._build_prompt(question, context_results)
        
        response = await self.openai_client.chat.completions.create(
            model=settings.OPENAI_MODEL,
            messages=messages,
            temperature=settings.OPENAI_TEMPERATURE,
            max_tokens=settings.OPENAI_MAX_TOKENS,
            stream=True  # â† é—œéµ
        )
        
        async for chunk in response:
            if chunk.choices[0].delta.content:
                yield chunk.choices[0].delta.content
```

**å‰ç«¯æ”¹å‹•**ï¼ˆ`ChatPage.tsx`ï¼‰ï¼š

```tsx
// ä½¿ç”¨ fetch + ReadableStream æ¥æ”¶ä¸²æµï¼ˆè§£æ text/event-streamï¼‰
const sendStreamMessage = async (content: string) => {
  // ç«‹å³é¡¯ç¤ºä½¿ç”¨è€…è¨Šæ¯
  setMessages(prev => [...prev, { role: 'user', content }]);
  
  // å»ºç«‹ä¸²æµé€£ç·š
  const response = await fetch('/api/v1/chat/stream', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json', Authorization: `Bearer ${token}` },
    body: JSON.stringify({ message: content, conversation_id: convId }),
  });
  
  const reader = response.body.getReader();
  const decoder = new TextDecoder();
  let assistantMsg = '';
  
  // å…ˆåŠ å…¥ç©ºçš„ assistant è¨Šæ¯
  setMessages(prev => [...prev, { role: 'assistant', content: '', streaming: true }]);
  
  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    
    const lines = decoder.decode(value).split('\n');
    for (const line of lines) {
      if (!line.startsWith('data: ')) continue;
      const data = JSON.parse(line.slice(6));
      
      if (data.type === 'token') {
        assistantMsg += data.content;
        // æ›´æ–°æœ€å¾Œä¸€æ¢ assistant è¨Šæ¯ï¼ˆé€å­—å¢é•·ï¼‰
        setMessages(prev => {
          const updated = [...prev];
          updated[updated.length - 1] = { ...updated[updated.length - 1], content: assistantMsg };
          return updated;
        });
      } else if (data.type === 'sources') {
        setSources(data.sources);
      }
    }
  }
};
```

**æ•ˆæœ**ï¼š

| æŒ‡æ¨™ | Before | After |
|------|--------|-------|
| é¦–å­—å‡ºç¾æ™‚é–“ | 5-15 ç§’ | < 1 ç§’ |
| æ„ŸçŸ¥å»¶é² | é«˜ï¼ˆç©ºç™½ç­‰å¾…ï¼‰ | ä½ï¼ˆé€å­—å‡ºç¾ï¼‰ |
| ä½¿ç”¨è€…é«”é©— | ç„¦æ…® | è‡ªç„¶å°è©±æ„Ÿ |

---

## P0ï¼šMulti-turn Context å¤šè¼ªå°è©±è¨˜æ†¶

### å•é¡Œ

ç›®å‰ `process_query()` æ¯æ¬¡æŸ¥è©¢å®Œå…¨ç¨ç«‹ï¼š

```python
# ç¾ç‹€ â€” chat_orchestrator.py
async def process_query(self, query: str, tenant_id: str, ...):
    # â† æ²’æœ‰ conversation history åƒæ•¸
    results = await self._retrieve(query, tenant_id)
    answer = await self._generate_answer(query, results)
    return answer
```

ä½¿ç”¨è€…å°è©±å ´æ™¯ï¼š
```
User: å…¬å¸ç‰¹ä¼‘å‡æœ‰å¹¾å¤©ï¼Ÿ
AI:   ä¾å¹´è³‡è¨ˆç®—ï¼Œæ»¿1å¹´7å¤©ï¼Œæ»¿2å¹´10å¤©...ï¼ˆæ­£ç¢ºå›ç­”ï¼‰

User: é‚£æœªä¼‘å®Œçš„æ€éº¼ç®—ï¼Ÿ   â† ã€Œé‚£ã€= ç‰¹ä¼‘å‡ï¼Œä½†ç³»çµ±ä¸çŸ¥é“
AI:   è«‹å•æ‚¨æƒ³äº†è§£ä»€éº¼ä¸»é¡Œï¼Ÿ  â† å¤±å»ä¸Šä¸‹æ–‡
```

### æ–¹æ¡ˆ

#### T7-2ï¼šæ­·å²æ³¨å…¥ + æ»‘å‹•çª—å£ + Token ç®¡ç†

> å‚™è¨»ï¼šæŸ¥è©¢æ”¹å¯«æœƒå¸¶ä¾†é¡å¤–æˆæœ¬èˆ‡å»¶é²ï¼Œå»ºè­°ã€Œæœ‰éœ€è¦æ‰å•Ÿç”¨ã€ï¼šä¾‹å¦‚æ–°å•é¡ŒåŒ…å«ä»£åè©ï¼ˆé‚£/å®ƒ/é€™å€‹/ä¸Šè¿°ï¼‰æˆ–æ˜é¡¯çœç•¥ä¸»è©æ™‚æ‰é€²è¡Œ `_contextualize_query()`ï¼Œå¦å‰‡ç›´æ¥ç”¨åŸ queryã€‚

```python
# app/services/chat_orchestrator.py

async def process_query(
    self, query: str, tenant_id: str, 
    conversation_id: str = None,  # æ–°å¢
    max_history_turns: int = 5,   # æ–°å¢ï¼šæœ€å¤šå¸¶å…¥æœ€è¿‘ N è¼ª
):
    # 1. å–å¾—æ­·å²å°è©±
    history = []
    if conversation_id:
        history = await self._get_conversation_history(
            conversation_id, max_turns=max_history_turns
        )
    
    # 2. ç”¨æ­·å²æ”¹å¯«æŸ¥è©¢ï¼ˆè§£æ±ºä»£åè©å•é¡Œï¼‰
    contextualized_query = await self._contextualize_query(query, history)
    
    # 3. ç”¨æ”¹å¯«å¾Œçš„æŸ¥è©¢åšæª¢ç´¢
    results = await self._retrieve(contextualized_query, tenant_id)
    
    # 4. å¸¶å…¥æ­·å² + æª¢ç´¢çµæœç”Ÿæˆå›ç­”
    answer = await self._generate_answer(query, results, history)
    return answer

async def _contextualize_query(self, query: str, history: list) -> str:
    """ç”¨ LLM å°‡æ¨¡ç³ŠæŸ¥è©¢æ”¹å¯«ç‚ºç¨ç«‹æŸ¥è©¢"""
    if not history:
        return query
    
    # è¼•é‡ promptï¼šåªåšæŸ¥è©¢æ”¹å¯«ï¼Œä¸åšå›ç­”
    messages = [
        {"role": "system", "content": (
            "æ ¹æ“šå°è©±æ­·å²ï¼Œå°‡ä½¿ç”¨è€…çš„æœ€æ–°å•é¡Œæ”¹å¯«ç‚ºä¸€å€‹ç¨ç«‹ã€å®Œæ•´çš„æŸ¥è©¢ã€‚"
            "åªè¼¸å‡ºæ”¹å¯«å¾Œçš„æŸ¥è©¢ï¼Œä¸è¦è§£é‡‹ã€‚å¦‚æœå•é¡Œå·²ç¶“å¤ æ˜ç¢ºï¼Œç›´æ¥åŸæ¨£è¼¸å‡ºã€‚"
        )},
        *[{"role": m["role"], "content": m["content"]} for m in history[-4:]],
        {"role": "user", "content": query}
    ]
    
    response = await self.openai_client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        temperature=0,
        max_tokens=200
    )
    return response.choices[0].message.content.strip()

def _build_messages_with_history(self, query, context, history):
    """çµ„è£å¸¶æ­·å²çš„ LLM messages"""
    messages = [{"role": "system", "content": self.SYSTEM_PROMPT}]
    
    # Token é ç®—ç®¡ç†
    total_tokens = 0
    max_history_tokens = 2000  # æ­·å²æœ€å¤šä½” 2000 tokens
    
    # å»ºè­°ï¼šä½¿ç”¨ tiktoken/å¯¦éš› tokenizer ä¼°ç®— tokensï¼ˆPhase 6 æ—¢æœ‰ TextChunker å·²ä½¿ç”¨ tokenizerï¼‰
    for msg in reversed(history):
      msg_tokens = len(msg["content"]) // 2  # ç²—ä¼°ï¼ˆææ¡ˆç”¨ï¼Œå¯¦ä½œæ™‚è«‹æ”¹ç‚º tokenizerï¼‰
        if total_tokens + msg_tokens > max_history_tokens:
            break
        messages.insert(1, {"role": msg["role"], "content": msg["content"]})
        total_tokens += msg_tokens
    
    # åŠ å…¥æª¢ç´¢ä¸Šä¸‹æ–‡
    messages.append({"role": "user", "content": self._format_context(query, context)})
    return messages
```

**æ•ˆæœç¯„ä¾‹**ï¼š

```
User: å…¬å¸ç‰¹ä¼‘å‡æœ‰å¹¾å¤©ï¼Ÿ
AI:   ä¾å¹´è³‡è¨ˆç®—ï¼Œæ»¿1å¹´7å¤©ï¼Œæ»¿2å¹´10å¤©...

User: é‚£æœªä¼‘å®Œçš„æ€éº¼ç®—ï¼Ÿ
      â†“ æ”¹å¯«ç‚º: ã€Œç‰¹ä¼‘å‡æœªä¼‘å®Œçš„å¤©æ•¸å¦‚ä½•è¨ˆç®—è£œå„Ÿï¼Ÿã€
AI:   ä¾å‹åŸºæ³•ç¬¬38æ¢ç¬¬4é …ï¼Œå¹´åº¦çµ‚çµæˆ–å¥‘ç´„çµ‚æ­¢æ™‚ï¼Œ
      æœªä¼‘ä¹‹ç‰¹ä¼‘å‡æ—¥æ•¸ï¼Œé›‡ä¸»æ‡‰æŠ˜ç™¼å·¥è³‡...  âœ… æ­£ç¢ºå›ç­”
```

---

## P1ï¼šChat UX å…¨é¢å‡ç´š

### T7-3ï¼šMarkdown æ¸²æŸ“å¼•æ“

**å•é¡Œ**ï¼šLLM å›è¦†å« Markdown èªæ³•ï¼ˆ`**ç²—é«”**`ã€`| è¡¨æ ¼ |`ã€`- åˆ—è¡¨`ï¼‰ï¼Œä½†å‰ç«¯ä»¥ç´”æ–‡å­—é¡¯ç¤ºã€‚

**æ–¹æ¡ˆ**ï¼š

```bash
# å‰ç«¯ä¾è³´
cd frontend && npm install react-markdown remark-gfm rehype-highlight
```

```tsx
// frontend/src/components/MarkdownRenderer.tsx
import ReactMarkdown from 'react-markdown';
import remarkGfm from 'remark-gfm';

export function MarkdownRenderer({ content }: { content: string }) {
  return (
    <ReactMarkdown
      remarkPlugins={[remarkGfm]}
      components={{
        table: ({ children }) => (
          <div className="overflow-x-auto my-2">
            <table className="min-w-full border-collapse border border-gray-300 text-sm">
              {children}
            </table>
          </div>
        ),
        th: ({ children }) => (
          <th className="border border-gray-300 bg-gray-100 px-3 py-1.5 text-left font-medium">
            {children}
          </th>
        ),
        td: ({ children }) => (
          <td className="border border-gray-300 px-3 py-1.5">{children}</td>
        ),
        ul: ({ children }) => <ul className="list-disc pl-5 my-1">{children}</ul>,
        ol: ({ children }) => <ol className="list-decimal pl-5 my-1">{children}</ol>,
        a: ({ href, children }) => (
          <a href={href} target="_blank" rel="noopener" className="text-blue-600 underline">
            {children}
          </a>
        ),
      }}
    >
      {content}
    </ReactMarkdown>
  );
}
```

### T7-4ï¼šä¾†æºå¼•ç”¨å±•é–‹

**ç¾æ³**ï¼šassistant è¨Šæ¯åº•éƒ¨æœ‰ `å…¬å¸å…§è¦`ã€`å‹å‹•æ³•è¦` éœæ…‹ badgeï¼Œç„¡æ³•é»æ“Šã€‚

**æ–¹æ¡ˆ**ï¼š

```tsx
// frontend/src/components/SourcePanel.tsx
function SourcePanel({ sources }: { sources: Source[] }) {
  const [expanded, setExpanded] = useState<number | null>(null);

  return (
    <div className="mt-3 border-t pt-2">
      <p className="text-xs text-gray-500 mb-1">ğŸ“ åƒè€ƒä¾†æºï¼ˆ{sources.length}ï¼‰</p>
      {sources.map((src, i) => (
        <div key={i} className="mb-1">
          <button
            onClick={() => setExpanded(expanded === i ? null : i)}
            className="flex items-center gap-2 text-sm text-left w-full hover:bg-gray-50 rounded px-2 py-1"
          >
            <span className={`px-1.5 py-0.5 rounded text-xs font-medium ${
              src.type === 'company_policy' 
                ? 'bg-blue-100 text-blue-700' 
                : 'bg-green-100 text-green-700'
            }`}>
              {src.type === 'company_policy' ? 'å…¬å¸å…§è¦' : 'å‹å‹•æ³•è¦'}
            </span>
            <span className="flex-1 truncate">{src.filename || src.title}</span>
            <span className="text-xs text-gray-400">
              {(src.score * 100).toFixed(0)}% ç›¸é—œ
            </span>
            <ChevronDown className={`w-4 h-4 transition-transform ${expanded === i ? 'rotate-180' : ''}`} />
          </button>
          
          {expanded === i && (
            <div className="ml-4 mt-1 p-2 bg-gray-50 rounded text-sm text-gray-700 border-l-2 border-blue-300">
              <p className="whitespace-pre-wrap">{src.content}</p>
              {src.metadata?.page && (
                <p className="text-xs text-gray-400 mt-1">ç¬¬ {src.metadata.page} é </p>
              )}
            </div>
          )}
        </div>
      ))}
    </div>
  );
}
```

> å‚™è¨»ï¼šå¯¦ä½œæ™‚è«‹å„ªå…ˆæ²¿ç”¨æ—¢æœ‰ `BrandingContext`/æ—¢æœ‰ Tailwind tokenï¼ˆé¿å…æ–°å¢ç¡¬ç·¨ç¢¼è‰²å½©èˆ‡æ¨£å¼ï¼‰ã€‚ä¸Šè¿°åƒ…ç‚ºäº’å‹•çµæ§‹ç¤ºä¾‹ã€‚

### T7-5ï¼šFeedback å›é¥‹ç³»çµ±

**è³‡æ–™æ¨¡å‹**ï¼š

```python
# app/models/feedback.py
class ChatFeedback(Base):
    __tablename__ = "chat_feedback"
    
    id = Column(UUID, primary_key=True, default=uuid4)
    tenant_id = Column(UUID, ForeignKey("tenants.id"), nullable=False, index=True)
    message_id = Column(UUID, ForeignKey("messages.id"), nullable=False)
    user_id = Column(UUID, ForeignKey("users.id"), nullable=False)
    rating = Column(SmallInteger, nullable=False)  # 1=ğŸ‘, 2=ğŸ‘
    category = Column(String(50))  # wrong_answer / incomplete / outdated / other
    comment = Column(Text)
    created_at = Column(DateTime, default=func.now())

    # å»ºè­°ï¼šåŒä¸€ä½¿ç”¨è€…å°åŒä¸€å‰‡è¨Šæ¯åƒ…å…è¨± 1 ç­†å›é¥‹ï¼ˆå¯æ›´æ–°ï¼‰ï¼Œé¿å…çŒç¥¨
    __table_args__ = (UniqueConstraint("user_id", "message_id", name="uq_feedback_user_message"),)
```

**API ç«¯é»**ï¼š

```python
# app/api/v1/endpoints/feedback.py
@router.post("/feedback")
async def submit_feedback(feedback: FeedbackCreate, current_user = Depends(get_current_user)):
    ...

@router.get("/feedback/stats")
async def feedback_stats(current_user = Depends(require_admin)):
    # è¿”å›ï¼šå¥½è©•ç‡ã€å·®è©•åŸå› åˆ†ä½ˆã€è¶¨å‹¢åœ–æ•¸æ“š
    ...
```

**å‰ç«¯ UI**ï¼š

```tsx
// åœ¨æ¯æ¢ assistant è¨Šæ¯åº•éƒ¨
<div className="flex items-center gap-2 mt-2">
  <button onClick={() => submitFeedback(msg.id, 2)} 
    className="p-1 rounded hover:bg-green-50">
    <ThumbsUp className="w-4 h-4 text-gray-400 hover:text-green-600" />
  </button>
  <button onClick={() => submitFeedback(msg.id, 1)}
    className="p-1 rounded hover:bg-red-50">
    <ThumbsDown className="w-4 h-4 text-gray-400 hover:text-red-600" />
  </button>
</div>
```

### T7-6ï¼šFollow-up å»ºè­°å•é¡Œ

**å¾Œç«¯**ï¼šåœ¨ LLM ç”Ÿæˆå›ç­”å¾Œï¼Œé¡å¤–ç”Ÿæˆ 2-3 å€‹è¿½å•å»ºè­°ã€‚

> å»ºè­°ï¼šä¸è¦æŠŠã€Œå»ºè­°å•é¡Œã€ç›´æ¥æ‹¼é€² answer æ–‡å­—ï¼ˆå®¹æ˜“æ±¡æŸ“å¼•ç”¨/Markdown/åŒ¯å‡ºï¼‰ã€‚è¼ƒç©©å¥åšæ³•æ˜¯å›å‚³ `suggested_questions: string[]` ä½œç‚ºç¨ç«‹æ¬„ä½ï¼ˆSSE äº¦å¯ç”¨ `type: 'suggestions'` äº‹ä»¶å‚³é€ï¼‰ã€‚

```python
# åœ¨ system prompt æœ«å°¾åŠ å…¥
FOLLOWUP_PROMPT = """
åœ¨å›ç­”çš„æœ€å¾Œï¼Œè«‹å¦èµ·ä¸€è¡Œè¼¸å‡º 3 å€‹å»ºè­°çš„è¿½å•å•é¡Œï¼Œæ ¼å¼ï¼š
[å»ºè­°å•é¡Œ]
1. ...
2. ...
3. ...
"""
```

**å‰ç«¯**ï¼šè§£æ `[å»ºè­°å•é¡Œ]` å€å¡Šï¼Œæ¸²æŸ“ç‚ºå¯é»æ“Šçš„æŒ‰éˆ•ã€‚

```tsx
// è§£æå»ºè­°å•é¡Œ
const suggestions = parseSuggestions(msg.content);

{suggestions.length > 0 && (
  <div className="flex flex-wrap gap-2 mt-3">
    {suggestions.map((q, i) => (
      <button key={i} onClick={() => sendMessage(q)}
        className="text-sm px-3 py-1.5 rounded-full border border-blue-200 
                   text-blue-700 hover:bg-blue-50 transition">
        {q}
      </button>
    ))}
  </div>
)}
```

---

## P2ï¼šMobile Responsive

### T7-9ï¼šè¡Œå‹•è£ç½®é©é…

**ç¾æ³å•é¡Œ**ï¼š
- å´é‚Šæ¬„ `w-64`ï¼ˆ256pxï¼‰å›ºå®šå¯¬åº¦ï¼Œæ‰‹æ©Ÿä¸Šä½”æ»¿è¢å¹•
- ç„¡æ¼¢å ¡é¸å–®æŒ‰éˆ•
- è¼¸å…¥å€åŸŸåœ¨å°è¢å¹•ä¸Šå¤ªçª„

**æ–¹æ¡ˆ**ï¼š

```tsx
// frontend/src/components/Layout.tsx â€” éŸ¿æ‡‰å¼å´é‚Šæ¬„
function Layout() {
  const [sidebarOpen, setSidebarOpen] = useState(false);
  
  return (
    <div className="flex h-screen">
      {/* Overlayï¼ˆè¡Œå‹•ç‰ˆï¼‰ */}
      {sidebarOpen && (
        <div className="fixed inset-0 bg-black/50 z-40 md:hidden" 
             onClick={() => setSidebarOpen(false)} />
      )}
      
      {/* å´é‚Šæ¬„ */}
      <aside className={`
        fixed md:static inset-y-0 left-0 z-50
        w-64 bg-white border-r transform transition-transform
        ${sidebarOpen ? 'translate-x-0' : '-translate-x-full'}
        md:translate-x-0
      `}>
        ...
      </aside>
      
      {/* ä¸»å…§å®¹ */}
      <main className="flex-1 flex flex-col min-w-0">
        {/* è¡Œå‹•ç‰ˆ Header + æ¼¢å ¡é¸å–® */}
        <header className="md:hidden flex items-center gap-3 p-3 border-b">
          <button onClick={() => setSidebarOpen(true)}>
            <Menu className="w-6 h-6" />
          </button>
          <h1 className="font-semibold">UniHR AI</h1>
        </header>
        ...
      </main>
    </div>
  );
}
```

---

## P2ï¼šå°è©±åŒ¯å‡º + é€²éšåˆ†æ

### T7-11ï¼šå°è©±åŒ¯å‡º

```python
# app/api/v1/endpoints/chat.py
@router.get("/chat/conversations/{id}/export")
async def export_conversation(
    id: UUID, 
    format: str = Query("markdown", enum=["markdown", "pdf"]),
    current_user = Depends(get_current_user)
):
    messages = await get_conversation_messages(id, current_user.tenant_id)
    
    if format == "markdown":
        content = render_markdown_export(messages)
        return Response(content, media_type="text/markdown",
                       headers={"Content-Disposition": f"attachment; filename=conversation_{id}.md"})
    elif format == "pdf":
        pdf_bytes = render_pdf_export(messages)
        return Response(pdf_bytes, media_type="application/pdf",
                       headers={"Content-Disposition": f"attachment; filename=conversation_{id}.pdf"})
```

### T7-12ï¼šRAG å“è³ªå„€è¡¨æ¿

æ–°å¢ Analytics é¢æ¿ï¼Œè¿½è¹¤ï¼š

| æŒ‡æ¨™ | æ•¸æ“šä¾†æº | å‘ˆç¾æ–¹å¼ |
|------|----------|----------|
| å¥½è©•ç‡ | `chat_feedback` | æŠ˜ç·šåœ–è¶¨å‹¢ |
| å·®è©•åŸå› åˆ†ä½ˆ | `chat_feedback.category` | åœ“é¤…åœ– |
| å¹³å‡å›æ‡‰æ™‚é–“ | `retrieval_trace.latency_ms` | æŠ˜ç·šåœ– |
| ç†±é–€å•é¡Œ Top 10 | `messages` èšé¡ | æ©«æ¢åœ– |
| ç„¡çµæœæŸ¥è©¢ç‡ | `retrieval_trace.sources_json` ç‚ºç©º | å–®ä¸€æŒ‡æ¨™ |
| ä¾†æºå¼•ç”¨åˆ†ä½ˆ | `company_policy` vs `labor_law` | å †ç–ŠæŸ±ç‹€åœ– |

### T7-13ï¼šå°è©±æœå°‹

```tsx
// å‰ç«¯ â€” å°è©±åˆ—è¡¨ä¸Šæ–¹åŠ æœå°‹æ¡†
<input 
  type="search" 
  placeholder="æœå°‹å°è©±..."
  value={searchQuery}
  onChange={(e) => setSearchQuery(e.target.value)}
  className="w-full px-3 py-1.5 text-sm border rounded"
/>
```

```python
# å¾Œç«¯ â€” å…¨æ–‡æœå°‹å°è©±
@router.get("/chat/conversations/search")
async def search_conversations(q: str, current_user = Depends(get_current_user)):
    results = await db.execute(
        select(Message).join(Conversation)
        .where(Conversation.tenant_id == current_user.tenant_id)
        .where(Message.content.ilike(f"%{q}%"))
        .order_by(Message.created_at.desc())
        .limit(20)
    )
    return results.scalars().all()
```

  > å‚™è¨»ï¼š`ILIKE '%...%'` åœ¨è³‡æ–™é‡å¤§æ™‚æ•ˆèƒ½æœƒå¿«é€Ÿä¸‹é™ã€‚è‹¥è¦é€²ä¸€æ­¥ç”¢å“åŒ–ï¼Œå»ºè­°æ”¹ç”¨ PostgreSQL Full-Text Searchï¼ˆ`tsvector`ï¼‰æˆ– trigram indexï¼ˆ`pg_trgm`ï¼‰ã€‚

### T7-14ï¼šTyping Indicator

åœ¨ç­‰å¾… AI å›è¦†æ™‚é¡¯ç¤ºæ‰“å­—æŒ‡ç¤ºå™¨å‹•ç•«ï¼š

```tsx
// frontend/src/components/TypingIndicator.tsx
function TypingIndicator() {
  return (
    <div className="flex items-center gap-1 px-4 py-2">
      <div className="flex gap-1">
        <span className="w-2 h-2 bg-gray-400 rounded-full animate-bounce [animation-delay:-0.3s]" />
        <span className="w-2 h-2 bg-gray-400 rounded-full animate-bounce [animation-delay:-0.15s]" />
        <span className="w-2 h-2 bg-gray-400 rounded-full animate-bounce" />
      </div>
      <span className="text-sm text-gray-400 ml-2">AI æ­£åœ¨è¼¸å…¥...</span>
    </div>
  );
}
```

---

## æŠ•å…¥å›å ±åˆ†æ

### æŠ•å…¥ vs å½±éŸ¿åŠ›çŸ©é™£

```
å½±éŸ¿åŠ› â†‘
  é«˜  â”‚ â˜… Streaming SSE    â˜… Multi-turn Context
      â”‚   Feedback System     Markdown Render
      â”‚   Source Expand        Guardrails
  ä¸­  â”‚   Follow-up Q's       Dark Mode
      â”‚   Chat Export          Mobile Responsive
      â”‚   RAG Dashboard
  ä½  â”‚   Typing Indicator    Chat Search
      â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ å¯¦ä½œè¤‡é›œåº¦
           ç°¡å–®ï¼ˆ1-2å¤©ï¼‰      ä¸­ç­‰ï¼ˆ3-5å¤©ï¼‰     è¤‡é›œï¼ˆ1é€±+ï¼‰
```

### å„é …ç›®é ä¼°å·¥æ™‚

| ID | é …ç›® | å¾Œç«¯å·¥æ™‚ | å‰ç«¯å·¥æ™‚ | ç¸½è¨ˆ | å„ªå…ˆç´š |
|----|------|----------|----------|------|--------|
| T7-1 | Streaming SSE | 4h | 4h | **1 å¤©** | ğŸ”´ P0 |
| T7-2 | Multi-turn Context | 6h | 2h | **1 å¤©** | ğŸ”´ P0 |
| T7-3 | Markdown æ¸²æŸ“ | 0 | 3h | **0.5 å¤©** | ğŸŸ  P1 |
| T7-4 | Source å±•é–‹ | 2h | 4h | **1 å¤©** | ğŸŸ  P1 |
| T7-5 | Feedback ç³»çµ± | 4h | 4h | **1 å¤©** | ğŸŸ  P1 |
| T7-6 | Follow-up å»ºè­° | 2h | 3h | **0.5 å¤©** | ğŸŸ  P1 |
| T7-9 | Mobile Responsive | 0 | 6h | **1 å¤©** | ğŸŸ¡ P2 |
| T7-11 | Chat Export | 4h | 2h | **1 å¤©** | ğŸŸ¡ P2 |
| T7-12 | RAG å“è³ªå„€è¡¨æ¿ | 4h | 6h | **1.5 å¤©** | ğŸŸ¡ P2 |
| T7-13 | Chat Search | 2h | 2h | **0.5 å¤©** | ğŸŸ¡ P2 |
| T7-14 | Typing Indicator | 0 | 1h | **0.5 å¤©** | ğŸŸ¡ P2 |
| | | | **åˆè¨ˆ** | **~9 å¤©** | |

### é ä¼°æ–°å¢ä¾è³´

| å¥—ä»¶ | ç”¨é€” | å±¤ç´š |
|------|------|------|
| `sse-starlette` | FastAPI SSE æ”¯æ´ | å¾Œç«¯ |
| `react-markdown` | Markdown æ¸²æŸ“ | å‰ç«¯ |
| `remark-gfm` | GFM è¡¨æ ¼/åˆªé™¤ç·š | å‰ç«¯ |
| `rehype-highlight` | ç¨‹å¼ç¢¼é«˜äº® | å‰ç«¯ï¼ˆé¸é…ï¼‰ |

---

## æŠ€è¡“åƒè€ƒè³‡æº

| åƒè€ƒ | é¡å‹ | ç”¨é€” |
|------|------|------|
| [OpenAI Streaming Guide](https://platform.openai.com/docs/api-reference/chat/create#chat-create-stream) | å®˜æ–¹æ–‡ä»¶ | T7-1 SSE ä¸²æµ |
| [FastAPI StreamingResponse](https://fastapi.tiangolo.com/advanced/custom-response/#streamingresponse) | å®˜æ–¹æ–‡ä»¶ | T7-1 å¾Œç«¯ä¸²æµ |
| [ChatGPT](https://chat.openai.com) | ç”¢å“åƒè€ƒ | T7-1 ä¸²æµ UX / T7-6 Follow-up |
| [Perplexity](https://perplexity.ai) | ç”¢å“åƒè€ƒ | T7-4 ä¾†æºå¼•ç”¨å±•é–‹ |
| [Claude](https://claude.ai) | ç”¢å“åƒè€ƒ | T7-3 Markdown æ¸²æŸ“ |
| [RAGAS](https://github.com/explodinggradients/ragas) | é–‹æºæ¡†æ¶ | T7-12 RAG å“è³ªè©•ä¼° |
| [react-markdown](https://github.com/remarkjs/react-markdown) | é–‹æºå¥—ä»¶ | T7-3 å‰ç«¯ Markdown |
| [AnythingLLM](https://github.com/Mintplex-Labs/anything-llm) | ç”¢å“åƒè€ƒ | T7-5 Feedback UI |

---

## å¯¦ä½œæ’ç¨‹å»ºè­°

```
Week 1ï¼ˆP0 æ ¸å¿ƒé«”é©—ï¼‰
â”œâ”€â”€ Day 1-2: T7-1 Streaming SSEï¼ˆå¾Œç«¯ + å‰ç«¯ï¼‰
â”œâ”€â”€ Day 3-4: T7-2 Multi-turn Contextï¼ˆæŸ¥è©¢æ”¹å¯« + æ­·å²æ³¨å…¥ï¼‰
â””â”€â”€ Day 5:   T7-3 Markdown æ¸²æŸ“ + T7-14 Typing Indicator

Week 2ï¼ˆP1 é«”é©—å¼·åŒ–ï¼‰
â”œâ”€â”€ Day 1:   T7-4 Source å¼•ç”¨å±•é–‹
â”œâ”€â”€ Day 2:   T7-5 Feedback ç³»çµ±ï¼ˆModel + API + UIï¼‰
â”œâ”€â”€ Day 3:   T7-6 Follow-up å»ºè­°
â””â”€â”€ Day 4-5: æ•´åˆæ¸¬è©¦ + Bug ä¿®å¾©

Week 3ï¼ˆP2 æ“´å±•åŠŸèƒ½ï¼‰
â”œâ”€â”€ Day 1:   T7-9 Mobile Responsive
â”œâ”€â”€ Day 2:   T7-11 Chat Export + T7-13 Chat Search
â”œâ”€â”€ Day 3-4: T7-12 RAG å“è³ªå„€è¡¨æ¿
â””â”€â”€ Day 5:   å…¨é¢æ¸¬è©¦ + README æ›´æ–° + éƒ¨ç½²

ç¸½è¨ˆï¼š3 é€±ï¼ˆ13 å€‹å·¥ä½œå¤© é ç•™ç·©è¡ï¼‰
```

---

## è®Šæ›´å½±éŸ¿ç¯„åœ

### å¾Œç«¯æª”æ¡ˆ

| æª”æ¡ˆ | è®Šæ›´é¡å‹ | ç›¸é—œä»»å‹™ |
|------|----------|----------|
| `app/services/chat_orchestrator.py` | é‡æ§‹ | T7-1, T7-2, T7-6 |
| `app/api/v1/endpoints/chat.py` | æ–°å¢ç«¯é» | T7-1, T7-11, T7-13 |
| `app/models/feedback.py` | æ–°å¢ | T7-5 |
| `app/schemas/feedback.py` | æ–°å¢ | T7-5 |
| `app/api/v1/endpoints/feedback.py` | æ–°å¢ | T7-5, T7-12 |
| `requirements.txt` | æ›´æ–° | T7-1 |
| `alembic/versions/xxx_add_feedback.py` | æ–°å¢ | T7-5 |

### å‰ç«¯æª”æ¡ˆ

| æª”æ¡ˆ | è®Šæ›´é¡å‹ | ç›¸é—œä»»å‹™ |
|------|----------|----------|
| `frontend/src/pages/ChatPage.tsx` | é‡æ§‹ | T7-1, T7-2, T7-14 |
| `frontend/src/components/MarkdownRenderer.tsx` | æ–°å¢ | T7-3 |
| `frontend/src/components/SourcePanel.tsx` | æ–°å¢ | T7-4 |
| `frontend/src/components/FeedbackButtons.tsx` | æ–°å¢ | T7-5 |
| `frontend/src/components/FollowUpSuggestions.tsx` | æ–°å¢ | T7-6 |
| `frontend/src/components/TypingIndicator.tsx` | æ–°å¢ | T7-14 |
| `frontend/src/components/Layout.tsx` | ä¿®æ”¹ | T7-9 |
| `frontend/package.json` | æ›´æ–° | T7-3 |

---

## æˆåŠŸæŒ‡æ¨™

| æŒ‡æ¨™ | ç›®å‰åŸºç·š | Phase 7 ç›®æ¨™ |
|------|----------|-------------|
| é¦–å­—å›æ‡‰æ™‚é–“ | 5-15 ç§’ | < 1 ç§’ |
| å¤šè¼ªå°è©±æˆåŠŸç‡ | 0%ï¼ˆä¸æ”¯æ´ï¼‰ | > 85% |
| ä½¿ç”¨è€…å›é¥‹æ”¶é›†ç‡ | 0%ï¼ˆç„¡æ©Ÿåˆ¶ï¼‰ | > 30% è¨Šæ¯æœ‰å›é¥‹ |
| Markdown æ­£ç¢ºæ¸²æŸ“ç‡ | 0% | 100% |
| è¡Œå‹•è£ç½®å¯ç”¨æ€§ | ä¸å¯ç”¨ | å®Œæ•´å¯ç”¨ |

---

> æœ¬ææ¡ˆåŸºæ–¼ Phase 6 å®Œæˆå¾Œçš„å®Œæ•´ç¨‹å¼ç¢¼å¯©æŸ¥ï¼Œåƒè€ƒ ChatGPTã€Claudeã€Perplexityã€AnythingLLM ç­‰ç”¢å“çš„æœ€ä½³å¯¦è¸ï¼Œçµåˆä¼æ¥­ HR SaaS çš„åˆè¦éœ€æ±‚è€Œåˆ¶å®šã€‚
